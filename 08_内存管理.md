---
title: 内存管理
author: Allwayso
update: 2025-12-30
status: Completed
---

## 内存管理基本概念

### 为什么要做内存管理

内存空间有限，并发程序需要同时、互相隔离、高效地使用大量内存

### 派生问题

1. 分配：空间管理，让多个程序能高效共存
2. 隔离：安全保护，防止程序互相干扰或修改操作系统
3. 共享：提高利用率，让不同进程使用相同的代码段
4. 扩展：突破物理限制，让大程序能在小内存上运行

### 虚拟地址空间

**核心目的**

1. 代码与位置解耦：程序在哪都能运行，不依赖于硬编码的物理地址
2. 程序员与硬件细节解耦：不需要硬编码程序物理地址
3. 进程与进程解耦：代码之间互相不知道物理地址，实现隔离

### 地址重定位

静态重定位在进程创建时确定一个固定的偏移量，物理地址此后不再改变；动态重定位利用基址寄存器存储偏移量，物理地址可随寄存器值改变而改变

### 内存保护

**重定位步骤**

1. 安检：检查逻辑地址是否超过界限寄存器中的最大长度，若越界则抛出段错误
2. 翻译：计算实际物理地址

> 硬隔离：界限寄存器的权限为内核级，程序无法改变

---

## 早期内存扩展技术

### 覆盖技术

将程序分为常驻区和覆盖段，非核心代码段只在使用时放入覆盖段。由于需要手动分配内存，编程复杂度极高，且频繁读写外存导致速度受限

### 交换技术

由操作系统自动调度，将暂时不需要运行的整个进程换出到交换区。其缺点在于颗粒度太粗，只要进程有一小部分在运行也必须换入整个进程

---

## 基本内存管理方案

### 固定分区

最早期的多道程序存储管理方式，将物理内存划分为若干固定大小的分区。其特点是分区边界在初始化时确定，痛点在于内碎片严重且无法运行大程序

> 内碎片：占着茅坑不拉屎。进程用不完固定的内存块，多余的部分又不能被别的进程使用

### 动态分区

系统根据进程实际需求按需分配内存。虽然解决了内碎片，但频繁的分割会导致大量细小的外部碎片，紧凑消除碎片的成本极高

> 外碎片：非连续的细碎的内存空间。在分配时，选取某个分区，分割出需要的内存大小，剩下的依然留在表中，就成为了外碎片

> 内外碎片的区别：内碎片是被某进程占用但没有被使用的；外碎片是没有被任何进程占用但是太小而无法使用的

#### 分区分配算法

| 算法名称      | 算法思路           | 优点                | 缺点                  |
|:--------- |:-------------- |:----------------- |:------------------- |
| 首次适应 (FF) | 从头部开始找第一个满足的空洞 | 速度最快，倾向于利用低地址空间   | 低地址产生细小外碎片，增加查找开销   |
| 循环首次 (NF) | 从上次查找结束位置开始往下找 | 空间分布均匀，查找起始时间短    | 破坏了大空间，导致大作业难进来     |
| 最佳适应 (BF) | 挑选能满足要求的最小空闲分区 | 最大限度保留大连续区，方便大作业  | 剩余空间极其微小（药渣），碎片问题最重 |
| 最坏适应 (WF) | 挑选能满足要求的最大空闲分区 | 剩下区依然很大，不容易产生细小碎片 | 很快切碎最大空间，导致大程序无处安身  |

> 这些分配方法原本是为了分配物理内存，在采用页式管理方法后不再需要这个功能，但是虚拟内存空间的分配仍然需要这些分配算法的变种

#### 外碎片解决方案

**回收**：在进程结束、归还所取内存（回收区）的同时，回收区邻近的空闲内存应该被合并起来，以最小地址为基地址，合并长度为空间大小

**紧凑**：移动所有已分配内存的进程，使其向内存一侧靠拢，从而将外碎片变为成片空间

> 页式管理不需要紧凑，紧凑本质上是为了获得连续的物理空间，而页式管理不需要连续物理空间
> 
> 但是回收的需求还是存在的，不过对于以下管理方式，回收的时候不需要经过合并过程

### 伙伴系统

动态分区的优化算法，通过内存分为$2^k$个小内存块，利用二进制算法提高合并效率

#### 分配逻辑：切分

当进程请求大小为 $n$ 的内存时，系统寻找大小为 $2^k$ 且大于等于 $n$ 的最小空闲块

1. 若存在满足要求的 $2^k$ 块，则直接分配
2. 若不存在，则找一个更大的块 $2^{k+1}$ 并将其等分为两个“伙伴”块
3. 其中一个伙伴用于分配，另一个伙伴进入对应大小的空闲链表
4. 若 $2^{k+1}$ 也不存在，则继续向上寻找更大块并递归切分

### 回收逻辑：合并

当一个内存块被释放时，系统会检查其“伙伴”块是否也处于空闲状态

1. **伙伴定义**：两个块大小相等、地址连续，且是从同一个大块中切分出来的
2. **自动合并**：如果伙伴也是空闲的，则将它们合并成一个两倍大的块
3. **递归合并**：合并后形成的新块会继续寻找它的伙伴进行合并，直到无法合并为止

> 与动态分区的对比：外碎片极少；结构简单，合并的效率远高于紧凑；产生一定的内碎片

> 在页式乃至段页式管理中的应用（被称为页分配器）：
> 
> 1.内核需求：一些内核数据结构还是硬要求连续物理空间，此时需要伙伴系统来提供成块内存
> 
> 2.作为批发商：段页式管理将连续空间分割为极小的页，这个连续空间的分配和回收是由批发商（伙伴系统）执行的

### 页式管理

通过页表将连续的页映射到离散的物理块，彻底消除了外部碎片。它实现了内存的高度自动化映射，但缺乏逻辑保护且难以满足动态增长的需求，通过页表实现页式管理

> 页式管理与虚拟内存的关系：注意到页式管理中出现了“逻辑空间”概念，也就是说这个时候进程的逻辑地址和物理地址开始分离，将程序员从直接操控物理地址中解放出来。
> 
> 1.通过将程序分页，只关注页的连续的逻辑地址，把分配物理地址的任务交给页表寄存器实现。2.不再手动从磁盘调取程序块，由操作系统自动调页，把不在内存中的一页搬入内存

**页表**：指操作系统为每个进程建立的一张映射索引表。它记录了进程的逻辑页（Page）与内存中的物理页框（Frame）之间的对应关系

#### 页表结构

页表由若干个页表项组成，每个表项主要包含以下两部分信息

1. **基本映射**：逻辑页号（通常作为索引）与对应的物理块号（页框号）

2. **状态与保护位**：
   
   **存在位 (Valid/Invalid)**：指示该页是否已加载进物理内存
   
   **读/写位 (R/W)**：控制该页是只读还是可读写
   
   **访问位 (Accessed)**：记录该页最近是否被访问过，用于置换算法
   
   **修改位 (Dirty)**：记录该页是否被写过，决定回收时是否需要写回磁盘

#### 转换逻辑

当 CPU 访问一个虚拟地址时，硬件（MMU）会自动执行以下步骤

1. **分离地址**：将虚拟地址对页长分别取商和取余，得到“页号”和“页内偏移量”
2. **查表**：利用页号作为索引，在页表中查找对应的物理块号
3. **组合**：将查到的“物理块号”与原有的“页内偏移量”拼接，得到最终的物理地址

#### 多级页表

由于虚拟内存远大于物理内存，如果单个页表覆盖整个虚拟空间，页表本身占用的物理内存就非常庞大了，所以引入了多级页表分割虚拟空间

为了减少页表占用的物理空间，采取如下策略：

1. **按需分配**：只有当进程真正使用了某个地址范围时，才会在内存中创建对应的下级页表。对于未使用的地址空间，对应的上级页表项为空，无需分配下级页表
2. **离散存储**：多级页表的每一级都可以散落在物理内存的不同位置，不再要求页表本身占据大片连续空间

> 当系统逻辑地址空间达到64位，页面大小为4kb=2^12B，每个页面包含2^9个页表项时，由于最底层页面需要寻址，占用了12位；其余64-12=52位需要由52/9=6级页表表示，最高层占不满；缺点：由于层级过多，造成查询开销提升；且多级页表的层级关系本身也要占用物理内存，却不能实际执行进程，造成了一定的内存浪费

#### 快表（TLB)

多级页表减少了页表占用的物理内存，但是带来了新的问题，即对没有被占用的物理块的查询开销变大，可能需要遍历多级页表，所以引入了快表存储最近被使用的页表项

采用快表后的转换逻辑：

1. **缓存映射**：当 CPU 需要翻译地址时，首先并行查询 TLB 
2. **命中处理**：如果 TLB 中存在该页的映射（命中），则直接获取物理块号，耗时几乎为零 
3. **失效处理**：如果 TLB 未命中，则继续走内存中的多级页表查询流程，并将查到的结果更新到 TLB 

> 对于多级页表在超大系统中存在的缺点，引入了哈希页表和反向页表

#### 哈希页表

使用哈希函数将巨大的虚拟页号映射到一个较小的哈希表项中 

1. **映射过程**：虚拟页号经过 Hash 运算，找到哈希表中的一个槽位（Bucket）

2. **冲突处理**：每个槽位维护一个链表，存储所有哈希值相同的页表项 

3. **查找匹配**：在链表中顺序比对虚拟页号，直到找到匹配的物理块号

#### 反向页表

反向页表彻底颠覆了设计思路：不再是每个进程一张表，而是**全系统仅一张表**，表项与物理内存的页框（Frame）一一对应 

1. **表项内容**：第 $i$ 个表项记录了“当前哪个进程的哪一页”正占据在物理块 $i$ 中 

2. **结构组成**：<进程标识符 PID, 虚拟页号, 保护位> 

3. **检索逻辑**：CPU 访问地址时，必须在这一张大表中搜索匹配的 PID 和页号。为了加速这种全表搜索，通常必须配合哈希表或关联存储器（Associative Register）使用

#### 三种方案对比

| 方案       | 索引依据   | 页表大小取决于    | 优点         | 缺点            |
|:-------- |:------ |:---------- |:---------- |:------------- |
| **多级页表** | 虚拟页号分段 | 虚拟空间大小及分布  | 逻辑直观，方便共享  | 64 位下层数多、查询慢  |
| **哈希页表** | 虚拟页号哈希 | 虚拟空间活跃程度   | 适合稀疏空间     | 哈希冲突会降低性能     |
| **反向页表** | 物理页框号  | **物理内存大小** | 极省内存，表大小固定 | 搜索困难，难以实现内存共享 |

> 现实中的 64 位系统（如 Intel x86-64 或 ARMv8）其实并未完全进入 64 位寻址。它们通常限制使用 48 位地址线，并继续采用优化后的 4 层页表。
> 
> 只有在服务器级、超大内存或特定架构（如早期 PowerPC 或 IA-64）中，哈希页表和反向页表才成为真正的主力。这种选择证明了：在硬件缓存（TLB）足够强大的情况下，成熟的分级方案依然比复杂的哈希方案更具工程稳定性

### 段式管理

按照程序的逻辑功能划分内存，每段大小不一。方便了信息的共享与保护并支持动态增长，但再次引发了外部碎片难题

### 段页式管理

先按逻辑分段以满足保护和共享需求，再在段内部分页以解决物理分配的碎片问题。它是目前主流操作系统普遍采用的终极平衡方案

> 评价：既拥有段式的逻辑完整性（好共享、好保护），又拥有页式的物理规则性（空间利用率极高）。内存管理方式的演进过程也可以看成是颗粒度的问题，需要在管理成本，空间利用率和逻辑完整性之间取得平衡。只有分配内存的大小、策略都合适的时候，才能兼顾三者

---

## 虚拟页式内存管理

### 基本思想

在分页系统基础上增加请求调页和页面置换功能。作业运行前仅装入部分页面，运行中发现缺页时触发中断并调入，实现小内存运行大程序

### 状态位与页表机制

**页表项字段**

1. 状态位：指示该页是否已调入内存
2. 访问字段：记录本页在一段时间内的访问情况
3. 修改位：指示页面在内存中是否被修改，决定置换时是否需写回
4. 外存地址：指出该页在磁盘上的存放位置

**地址变换**

算法名称：请求分页地址变换算法

---

## 页面置换算法对比

| 算法名称          | 核心策略           | 性能评价         | 实现难度      |
|:------------- |:-------------- |:------------ |:--------- |
| 最佳置换 (OPT)    | 淘汰以后永不使用或最久不用的 | 理论最优，缺页率最低   | 无法实现      |
| 先进先出 (FIFO)   | 淘汰最先进入内存的页面    | 可能产生Belady异常 | 最简单       |
| 最近最久未使用 (LRU) | 淘汰最近一段时间最久未使用的 | 性能最接近OPT     | 较复杂，需硬件支持 |
| 时钟置换 (CLOCK)  | 循环扫描访问位，0替换1置零 | 性能与开销的平衡点    | 适中        |

---

## 虚存性能的影响因素

### 抖动与工作集

**抖动现象**

由于分配物理块太少导致页面频繁换入换出，使处理机大部分时间用于磁盘I/O，CPU利用率急剧下降

**工作集模型**

工作集指进程在某段时间间隔内实际访问页面的集合。系统分配给进程的物理块数应能容纳其工作集以防止抖动

### 其它因素

缺页率受页面大小、程序编写方式（是否符合局部性原理）以及分配物理块数的影响

---

## 虚存相关技术

### 关键机制

1. 写时复制 (COW)：fork时父子进程共享页面，仅在修改时执行物理复制
2. 内存映射文件 (mmap)：将磁盘文件映射到进程虚拟地址空间，减少数据拷贝开销

### 补充标记

~ 交换技术：系统自动管理进程在内存与对换区之间的整体换入换出

~ 覆盖技术：早期程序员手动管理内存的技术，现已淘汰

~ 内存保护：利用页表存取控制位实现地址越界检查和访问权限控制
